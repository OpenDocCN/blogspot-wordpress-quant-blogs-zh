<!--yml
category: 未分类
date: 2024-05-12 21:47:07
-->

# Falkenblog: The Nobel Goes To ...

> 来源：[http://falkenblog.blogspot.com/2009/10/nobel-goes-to.html#0001-01-01](http://falkenblog.blogspot.com/2009/10/nobel-goes-to.html#0001-01-01)

Mankiw

[lists](http://gregmankiw.blogspot.com/2009/10/nobel-odds.html)

Eugene Fama and Paul Romer as huge favorites. If they give it to Fama, they should give it to French, even though Fama has a much deeper set of contributions (the definition of the Efficient Markets Theory in 1970), because for the past 20 years most of their papers have been joint, and they have really dominated the debate on issues from models of bonds to equities. I don't know much about Romer's work, but it's at least as influential as Krugman's in the idea that increasing returns to scale are very important in growth, so I presume that means he'll get it if he lives long enough.

As I note in

[my book](http://www.defprob.com/video/)

, I'm a rather strong critic of Fama's work on equity risk factors. Yet, in terms of impact, Fama is clearly a force. Further, I truly admire his style, in that his articles are very clear, unlike most 'top' financial economists. Many financial economists in the 80's were focused on abstruse issues of econometrics that turned out irrelevant (eg, the simultaneous estimation of betas and the zero-beta return, exact finite sample distributions). After Fama-French 1992, where they introduced the three factor model (the market, value, and size factors) and basically made it safe to say the CAPM did not work (Fama graciously admits this paper merely consolidated what everyone knew studying the value and size 'anomalies' for the prior decade), finance became much more practically focused, more relevant.

But, I'd have to say, this isn't a good year for giving the prize to someone so closely identified with the Efficient Markets Hypothesis. Barro, Sargent, or Sims seem like good choices, as all are part of the cannon, each with essential insights. Sims really put the fork in the Keynesian Macro Model mania of the 1960s and 70s, showing that simple vector autoregressions outperformed these models (

[Macroeconomics and Reality](http://www.eduardoloria.name/articulos/Sims.pdf)

, 1980). VARs remain a

[key tool](http://www.crei.cat/conferences/Macroeconomics_and_Reality,_25_years_later/papers_available.html)

for macroeconomists, and Sims did a lot of work in this area. I imagine few Fed briefings do not involve stimulus-response estimates generated via VARs. It's a very applied approach, because it basically says, don't be too specific in your causal model (like the Keynesian Macro models), yet, it does not suggest one use totally nonparametric, or unidentified models. He basically says, find the main variables that should affect things (like GDP) via theory, then look at how the past values of those predictors explain the predicted variables, and plot them in a graph.

Barro highlighted that if people were rational, borrowing money is the same as raising taxes, because people anticipate future taxes, extinguishing any stimulus via deficit spending (

[Are Government Bonds Net Wealth?](The%20phrase,)

1974). The phrase, "Ricardian equivalence," has become well known among scholars in macroeconomics and public finance (James Buchanon noted some writing of Ricardo's that had some inklings of this back in the early 1800s). It refers to a situation in which taxation and government borrowing have the same effects on the economy. The equivalence can arise because government borrowing tends to increase future taxes (to pay interest and principal on the public debt) and, as long as the present value is the same, people may react to anticipated future taxes just as they do to current taxes. To put it another way, a reduction in the government's saving due to a current budget deficit may induce the private sector to save correspondingly more. The total of national saving is then invariant to the government's borrowing. No more Keynesian stimulus effect from government borrowing.

Lastly, Sargent is a cofounder of the new classical macroeconomics based on rational expectations and dynamic stochastic models. A lot of work he did was highly technical, but influential economists write for economists, and his books on Macroeconomic Theory and Dynamic Macroeconomic Theory really concisely described the macroeconomic toolkit better than any other books of his generation. In those books, he takes models like Robert Lucas's Island Model, the Modigliani-Miller Theory, or Barro's Ricardian Equivalence, and boils them down to their essentials. His paper

[Some Unpleasant Monetarist Arithmetic](http://www.minneapolisfed.org/research/QR/QR531.pdf)

(1981) nicely shows via some simple algebra that if fiscal policy is independent of monetary policy it can generate inflation by basically forcing future seignorage to pay off debt. This is very relevant to countries in excessive deficit spending mode.

Interestingly, as technical as these guys are, their most influential work is much more accessible than work that came later. Many who saw their success incorrectly inferred that it was their technical expertise that made them successful, and so instead of extending their economic ideas, tried to simply create more complicated mathematics (eg, Kalman filters instead of VARs, Judd's growth models). Similarly, I remember in grad school my professors then thought of Fama as insufficiently rigorous compared to say Gibbons, Ross, or Shanken. I doubt they remember that now. I think Macro is a mess, but these guys kept it from being a whole lot less messier. I guess that's seeing the glass half full.

Update: it appears Barack Obama's chances of winning the Nobel for his stimulus plan is not insignificant.