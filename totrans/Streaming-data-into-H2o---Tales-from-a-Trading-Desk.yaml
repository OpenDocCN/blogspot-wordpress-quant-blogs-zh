- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-05-18 05:33:46'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-18 05:33:46
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Streaming data into H2o | Tales from a Trading Desk
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据流式传输到 H2o | 交易桌旁的故事
- en: 来源：[https://mdavey.wordpress.com/2016/04/20/streaming-data-into-h2o/#0001-01-01](https://mdavey.wordpress.com/2016/04/20/streaming-data-into-h2o/#0001-01-01)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://mdavey.wordpress.com/2016/04/20/streaming-data-into-h2o/#0001-01-01](https://mdavey.wordpress.com/2016/04/20/streaming-data-into-h2o/#0001-01-01)
- en: Streaming data into H2o
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据流式传输到 H2o
- en: Not something that appears widely publicised, which in my view is strange given
    the real-time world we live in these days, but after some web searching I found
    a relevant article on the H2O World 2015 Training [site](http://learn.h2o.ai/content/tutorials/streaming/storm/index.html).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个广泛公开宣传的内容，鉴于我们如今生活在实时世界中，这在我看来很奇怪，但在网上搜索后，我在 H2O World 2015 培训 [网站](http://learn.h2o.ai/content/tutorials/streaming/storm/index.html)
    上找到了一篇相关文章。
- en: databrick [streaming](https://databricks.com/blog/category/engineering/streaming)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: databrick [流式处理](https://databricks.com/blog/category/engineering/streaming)
- en: Diving into Spark Streaming’s [Execution](https://databricks.com/blog/2015/07/30/diving-into-spark-streamings-execution-model.html)
    Model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨 Spark Streaming 的[执行模型](https://databricks.com/blog/2015/07/30/diving-into-spark-streamings-execution-model.html)
- en: Improvements to Kafka [integration](https://databricks.com/blog/2015/03/30/improvements-to-kafka-integration-of-spark-streaming.html)
    of Spark Streaming
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 Kafka [集成](https://databricks.com/blog/2015/03/30/improvements-to-kafka-integration-of-spark-streaming.html)
    的改进
- en: 'How-to: Build a Machine-Learning App Using Sparkling Water and Apache [Spark](http://blog.cloudera.com/blog/2015/10/how-to-build-a-machine-learning-app-using-sparkling-water-and-apache-spark/)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建：使用 Sparkling Water 和 Apache [Spark](http://blog.cloudera.com/blog/2015/10/how-to-build-a-machine-learning-app-using-sparkling-water-and-apache-spark/)
    构建机器学习应用
- en: Real-time Predictions With H2O on [Storm](http://learn.h2o.ai/content/tutorials/streaming/storm/index.html)
    isn’t quite what I was looking for, I’m more interested in Apache Kafka.  However,
    its close enough to the problem to be useful 🙂
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 H2O 在 [Storm](http://learn.h2o.ai/content/tutorials/streaming/storm/index.html)
    上进行实时预测并不是我想要找的，我更感兴趣的是 Apache Kafka。然而，它足够接近我要解决的问题，是有用的 🙂
- en: Source code can be found [here](https://github.com/h2oai/h2o-tutorials/tree/master/tutorials/streaming/storm). TestH2ODataSpout.java
    is the fake real-time data.  [H2OStormStarter.java](https://github.com/h2oai/h2o-tutorials/blob/master/tutorials/streaming/storm/H2OStormStarter.java)
    is the interesting code, which consumes the real-time data, and pushing results out
    via the collector emit() and ack() functions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码可以在 [这里](https://github.com/h2oai/h2o-tutorials/tree/master/tutorials/streaming/storm)
    找到。TestH2ODataSpout.java 是假实时数据。 [H2OStormStarter.java](https://github.com/h2oai/h2o-tutorials/blob/master/tutorials/streaming/storm/H2OStormStarter.java)
    是有趣的代码，它消耗实时数据，并通过收集器的 emit() 和 ack() 函数输出结果。
- en: PredictionBolt emits tuples via the collector to ClassifierBolt who write the
    data to a file (out) and also emits the classification result to the collector.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 预测 bolt 通过收集器发出元组到 ClassifierBolt，后者将数据写入文件（out）并也将分类结果发到收集器。
- en: The cheat is that ClassifierBolt write to a file (out), which is read by the
    JS code.  In reality the results from ClassifierBolt should probably go via a
    websocket to the HTML user interface.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 窍门是 ClassifierBolt 写入一个文件（out），这被 JS 代码读取。实际上 ClassifierBolt 的结果可能应该通过 websocket
    传输到 HTML 用户界面。
- en: Net out, using Storm, Kafka or other technology is irrelevant, the key is exporting the
    model as a Java POJO via R, and h2o.download_pojo().
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 净输出，使用 Storm、Kafka 或其他技术无关紧要，关键是将模型作为 Java POJO 通过 R 导出，然后使用 h2o.download_pojo()。
- en: ~ by mdavey on April 20, 2016.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ~ 由 mdavey 于 2016 年 4 月 20 日发表。
- en: Posted in [Data](https://mdavey.wordpress.com/category/data/)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 发布在 [数据](https://mdavey.wordpress.com/category/data/)
- en: 'Tags: [H2O](https://mdavey.wordpress.com/tag/h2o/), [Kafka](https://mdavey.wordpress.com/tag/kafka/),
    [MachineLearning](https://mdavey.wordpress.com/tag/machinelearning/)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 标签：[H2O](https://mdavey.wordpress.com/tag/h2o/)，[Kafka](https://mdavey.wordpress.com/tag/kafka/)，[机器学习](https://mdavey.wordpress.com/tag/machinelearning/)
