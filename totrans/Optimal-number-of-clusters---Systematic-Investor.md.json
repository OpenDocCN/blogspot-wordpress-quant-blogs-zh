["```\n\n###############################################################################\n# Load Systematic Investor Toolbox (SIT)\n# https://systematicinvestor.wordpress.com/systematic-investor-toolbox/\n###############################################################################\nsetInternet2(TRUE)\ncon = gzcon(url('http://www.systematicportfolio.com/sit.gz', 'rb'))\n    source(con)\nclose(con)\n\n\t#*****************************************************************\n\t# Load historical data for ETFs\n\t#****************************************************************** \n\tload.packages('quantmod')\n\n\ttickers = spl('GLD,UUP,SPY,QQQ,IWM,EEM,EFA,IYR,USO,TLT')\n\n\tdata <- new.env()\n\tgetSymbols(tickers, src = 'yahoo', from = '1900-01-01', env = data, auto.assign = T)\n\t\tfor(i in ls(data)) data[[i]] = adjustOHLC(data[[i]], use.Adjusted=T)\n\n\tbt.prep(data, align='remove.na')\n\n\t#*****************************************************************\n\t# Create Clusters\n\t#****************************************************************** \n\t# compute returns\n\tret = data$prices / mlag(data$prices) - 1\n\t\tret = na.omit(ret)\t\t\n\n\t# setup period and method to compute correlations\n\tdates = '2012::2012'\n\tmethod = 'pearson'\t# kendall, spearman\n\n\tcorrelation = cor(ret[dates], method = method)    \n        dissimilarity = 1 - (correlation)\n        distance = as.dist(dissimilarity)\n\n\t# get first 2 pricipal componenets\n\txy = cmdscale(distance)\n\n```", "```\n\n    #*****************************************************************\n\t# Determine number of clusters\n\t#****************************************************************** \n\tn = ncol(data$prices)\n\t\tn1 = ceiling(n*2/3)\n\n\t# percentage of variance explained by clusters\n\tp.exp = rep(0,n1)\n\n\t# minimum correlation among all components in each cluster\t\n\tmin.cor = matrix(1,n1,n1)  \n\n\tfor (i in 2:n1) {\n\t\tfit = kmeans(xy, centers=i, iter.max=100, nstart=100)\n\t\tp.exp[i] = 1- fit$tot.withinss / fit$totss\n\n\t\tfor (j in 1:i) {\n\t\t\tindex = fit$cluster == j\n\t\t\tmin.cor[i,j] = min(correlation[index,index])\n\t\t}\n\t}\n\n\t# minimum number of clusters that explain at least 90% of variance\n\tmin(which(p.exp > 0.9))\n\n\t# minimum number of clusters such that correlation among all components in each cluster is at least 40%\n\t# will not always work\n\tmin(which(apply(min.cor[-1,],1,min,na.rm=T) > 0.4)) + 1\n\n\t# number of clusters based on elbow method\n\tfind.maximum.distance.point(p.exp[-1]) + 1\n\n```", "```\n\nmin(which(p.exp > 0.9))\n[1] 4\n\n```", "```\n\nmin(which(apply(min.cor[-1,],1,min,na.rm=T) > 0.4)) + 1\n[1] 5\n\n```", "```\n\nfind.maximum.distance.point(p.exp[-1]) + 1\n[1] 4\n\n```", "```\n\n\t#*****************************************************************\n\t# Create Plot\n\t#****************************************************************** \t\n\tload.packages('cluster')\n\tfit = kmeans(xy, 4, iter.max=100, nstart=100)\n\tclusplot(xy, fit$cluster, color=TRUE, shade=TRUE, labels=3, lines=0, plotchar=F, \n\t\tmain = paste('Major Market Clusters over', dates, ', 4 Clusters'), sub='')\n\n\tfit = kmeans(xy, 5, iter.max=100, nstart=100)\n\tclusplot(xy, fit$cluster, color=TRUE, shade=TRUE, labels=3, lines=0, plotchar=F, \n\t\tmain = paste('Major Market Clusters over', dates, ', 5 Clusters'), sub='')\n\n```"]