- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-18 13:46:26'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Return Decomposition via Mixing | Quantivity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://quantivity.wordpress.com/2011/12/28/estimating-mixture-index-return-decomposition-via-maximum-likelihood/#0001-01-01](https://quantivity.wordpress.com/2011/12/28/estimating-mixture-index-return-decomposition-via-maximum-likelihood/#0001-01-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A variety of techniques exist for estimating parameters of the return decomposition
    model, previously introduced in [Index Return Decomposition](https://quantivity.wordpress.com/2011/12/14/index-return-decomposition/).
    This post considers estimation of an *independent mixture model* via maximum likelihood
    (MLE), a workhorse of frequentist statistics and always a nice place to begin.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall ![z](img/7d74f7d8fdd6545e22c6dd9de0af53b3.png) is *unobserved*, and
    thus the model cannot be directly estimated via MLE. Thus, need to decide how
    to approach estimation for this latent variable. One way is to be naive, and simply
    assume ![z](img/7d74f7d8fdd6545e22c6dd9de0af53b3.png) is the deterministic difference
    in return between stock and index (technically, this generates a [profile likelihood](http://en.wikipedia.org/wiki/Likelihood_function#Profile_likelihood)
    as formalized by [Severini and Wong [1992]](http://people.csail.mit.edu/~jrennie/trg/papers/severini-conditionally-92.pdf),
    which [Murphy and Van Der Vaart [2000]](http://www.jstor.org/pss/2669386) verify
    is well-behaved consistent with exact likelihood):'
  prefs: []
  type: TYPE_NORMAL
- en: '![z_t = r_t - i_t ](img/9406f569aca4e251c598dbe26d85eef1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This assumption permits focus on estimating ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png),
    providing insight into the *mixing behavior* of the return being decomposed: if
    a stock return behaves like its index, then mixing is low with small ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png)
    (in the limit, ![\alpha = 0](img/52b5c00309e065e19db837bc8b91a752.png) when a
    stock behaves identical to its index, as no mixing is required); in contrast,
    the stock return behaves independent from its index on a regular basis, then mixing
    is high with a large ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Autocorrelation of ![i](img/6aed483d693a0743f647c27ec4372c2a.png) and ![z](img/7d74f7d8fdd6545e22c6dd9de0af53b3.png)
    is worth consideration, as that helps determine whether time indexing is required
    for ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png). For returns with insignificant
    autocorrelation (common for *signed* equity returns), the time index is dropped
    and a single ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png) is estimated.
    Yet, *conditional dependence* often exists between ![i](img/6aed483d693a0743f647c27ec4372c2a.png)
    and ![z](img/7d74f7d8fdd6545e22c6dd9de0af53b3.png), consistent with previous posts
    in the [Proxy / Cross Hedging](https://quantivity.wordpress.com/2011/10/02/proxy-cross-hedging/)
    series (illustrating r-z copula for CRM / QQQ example below):'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/d52a149560df398f8f8a27d96db1a5c4.png "z-r-empirical-copula")](https://quantivity.wordpress.com/wp-content/uploads/2011/12/z-r-empirical-copula.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use of this identity for ![z_i](img/1088d8d1a22a00dc3cf8fd0af3dbde55.png) transforms
    the decomposition model into:'
  prefs: []
  type: TYPE_NORMAL
- en: '![r_t = s_t \left[ \alpha_t | (r_t - i_t) | + (1 - \alpha_t) \beta | i_t |
    \right] ](img/f32c42b7f1f93f3ffdcab23e1872b887.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The model is further simplified into a familiar *independent mixture model*
    by dropping sign ![s_t](img/3d34b6bd645c53954926164c36a40ae9.png) and ![\beta](img/e59dd600f7eb22f952e355797bceba2e.png),
    and estimating via MLE using density ![f](img/f6f5c905b764a946a65bee80b6736fe6.png)
    and return distribution functions ![\phi_i](img/be9f6c685169bb91b421eb34dc9abdb4.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![f(r_t; \boldsymbol{\theta}) = \alpha \phi_1(r_t - i_t) + (1 - \alpha) \phi_2(i_t)  ](img/4882ebdb6e48051d820ea02018a5f2f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'MLE estimation requires assumption of parametric distributions for ![\phi_i](img/be9f6c685169bb91b421eb34dc9abdb4.png),
    of which common choices from the literature are normal, student-t, skew-t, or
    skew hyperbolic student-t ([Aas and Haff [2006]](http://www.econ.ku.dk/fru/conference/Programme/Sunday/F4/Aas_226.pdf)).
    Next question is how to estimate the ![\boldsymbol{\theta}](img/fd899b1331662dd5d038aff6ddde37b9.png)
    parameters: ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png) and family of
    ![\phi_i](img/be9f6c685169bb91b421eb34dc9abdb4.png) parameters (*e.g.* ![\mu_i](img/9840e9175f3add00a2433beec43402e8.png)
    and ![\sigma_i](img/63292fcbee22336be0cef01660cacbe6.png) if ![\phi_i](img/be9f6c685169bb91b421eb34dc9abdb4.png)
    is assumed to be normal). As ![i_t](img/d1ba04e50950b99d9eabd6f208278285.png)
    is observed, one way to proceed is via two-step estimation:'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate ![\phi_2](img/99322676b5ef63b1e34f31e85ad3be1b.png) parameters via
    MLE from ![i_t](img/d1ba04e50950b99d9eabd6f208278285.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jointly estimate ![\alpha](img/9a53e012ad26523af8c1a6778d340c3f.png) and ![\phi_1](img/bc97634b37bdf282a3d4ff84cec42357.png)
    parameters via MLE on the mixture, holding ![\phi_2](img/99322676b5ef63b1e34f31e85ad3be1b.png)
    parameters constant
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For both, recall the likelihood ![\mathcal{L} ](img/8639f7e55dad758d20f029b786e751d6.png),
    and log likelihood ![ln \mathcal{L} ](img/4c1a27f1b1e4e4bbf2a5638e366df39a.png),
    are defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\mathcal{L} = \prod\limits_{t=1}^T f(r_t; \boldsymbol{\theta}) ](img/69dd76d6496656f37973a0ce3b9e18d5.png)'
  prefs: []
  type: TYPE_IMG
- en: '![\ln \mathcal{L} = \sum\limits_{t=1}^T \ln f(r_t; \boldsymbol{\theta}) ](img/7eed25417f5e550d7141b12079f83278.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From which MLE of the mixture is maximization of the likelihood over ![\boldsymbol{\theta}](img/fd899b1331662dd5d038aff6ddde37b9.png),
    where log is chosen for numeric stability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![\displaystyle \max_{\boldsymbol{\theta}} \ln \mathcal{L} = \max_{\boldsymbol{\theta}}
    \sum\limits_{t=1}^T \left( \ln \left[ \alpha (r_t - i_t) + (1 - \alpha) i_t \right]
    \right)](img/cdf953d7d59bf32767f8f0679d0f2692.png)'
  prefs: []
  type: TYPE_IMG
- en: This optimization can be performed numerically in R via minimization using `DEoptim`
    of the negative log likelihood `negLogLikeFun` (negative is due to minimization
    in `DEoptim` versus maximization of ![\ln \mathcal{L}](img/4967bf980eb26ee995662054c8a70def.png)).
    `DEoptim` is chosen due to rapid convergence on non-smooth global optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, continuing the example of CRM / QQQ introduced in the previous
    posts on [Proxy / Cross Hedging](https://quantivity.wordpress.com/2011/10/02/proxy-cross-hedging/)
    generates the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'These results correspond to the following density functions for the skew-t
    mixture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/bd68b0d9020342a45209d7d160be8274.png "return-decomp-mixture-densities-skewt")](https://quantivity.wordpress.com/wp-content/uploads/2011/12/return-decomp-mixture-densities-skewt2.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'One interesting observation of these densities is their location parameters
    are on opposing side of zero: ![z](img/7d74f7d8fdd6545e22c6dd9de0af53b3.png) has
    positive location, while ![i](img/6aed483d693a0743f647c27ec4372c2a.png) has negative
    location. One interpretation of this is positive returns from CRM disproportionately
    originate from the idiosyncratic ![z_t](img/74d890ac7e079882a239837ea3afdf8c.png),
    while negative returns originate from the index ![i_t](img/d1ba04e50950b99d9eabd6f208278285.png).
    Economically, this is plausible: positive news is often idiosyncratic, while negative
    news is often market-wide.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Several additional inferences can be drawn from these results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Model selection: likelihood suggests skew-t is the preferred model, indicating
    long tails and skewness (matching stylized facts)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mixing: ![\alpha = 0.24](img/2ba46f580ddd22c68f4055ca912bb243.png) indicating
    that over 75% of CRM returns are determined by the corresponding QQQ index; remaining
    25% are determined by the unobserved ![z](img/7d74f7d8fdd6545e22c6dd9de0af53b3.png)
    return series'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tails: CRM ![\phi_1](img/bc97634b37bdf282a3d4ff84cec42357.png) df = 2.89 which
    indicates significantly thicker tails than QQQ ![\phi_2](img/99322676b5ef63b1e34f31e85ad3be1b.png)
    df = 26.56 (matching stylized facts for individual stocks versus indices)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subsequent posts may consider alternative estimation techniques for this model.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'R code for generating two-stage MLE estimation of return decomposition via
    mixing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
