- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-18 05:36:24'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Logstash: Geoip for Internal Networks – Part 2 | Tales from a Trading Desk'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://mdavey.wordpress.com/2016/01/20/logstash-geoip-for-internal-networks-part-2/#0001-01-01](https://mdavey.wordpress.com/2016/01/20/logstash-geoip-for-internal-networks-part-2/#0001-01-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Logstash: Geoip for Internal Networks – Part 2'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Continuing with logstash.  If your doing anything with TopBeat, then consider
    the dashboards, available [here](https://www.elastic.co/guide/en/beats/libbeat/1.0.1/getting-started.html#load-kibana-dashboards).
     Using FileBeats and TopBeats to feed logstash, will effectively mean logstash
    receives both streams via port 5044\.  In your logstash config, your may want
    to insert the data into different ElasticSearch index’s.  One way tot do this
    is to check the input type of data from Beats:'
  prefs: []
  type: TYPE_NORMAL
- en: filter {
  prefs: []
  type: TYPE_NORMAL
- en: if [type] == “system” or [type] == “filesystem” or [type] == “process” {
  prefs: []
  type: TYPE_NORMAL
- en: mutate {
  prefs: []
  type: TYPE_NORMAL
- en: add_field => { “_IndexName” => “%{type}” }
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: 'And then in the output section, change the index name as appropriate:'
  prefs: []
  type: TYPE_NORMAL
- en: elasticsearch {
  prefs: []
  type: TYPE_NORMAL
- en: index => “%{_IndexName}-%{+YYYY.MM.dd}”
  prefs: []
  type: TYPE_NORMAL
- en: ~ by mdavey on January 20, 2016.
  prefs: []
  type: TYPE_NORMAL
- en: Posted in [Data](https://mdavey.wordpress.com/category/data/)
  prefs: []
  type: TYPE_NORMAL
