<!--yml

类别：未分类

日期：2024-05-18 15:28:43

-->

# ReInventing the Wheel | Tr8dr

> 来源：[`tr8dr.wordpress.com/2015/01/27/reinventing-the-wheel/#0001-01-01`](https://tr8dr.wordpress.com/2015/01/27/reinventing-the-wheel/#0001-01-01)

我想我已经足够大了，以至于在软件基础设施和金融科技领域看到过多次轮子被重新发明。不幸的是，下一代轮子并不总是更好的，而且常常由于年轻人的激情而忽略先前“轮子”的教训。话说回来，我们都知道，有时创新是一个前进三步、后退两步的过程。

最近影响我的两个例子。

**HDFS**

一个例子是在技术领域中的 Hadoop/HDFS，其中 Amdahl 定律被完全忽略了（即保持数据靠近计算以实现并行化）。当向 HDFS 写入数据时，HDFS 将在节点之间分配数据块，但没有明确的方式来控制数据/节点亲和性。HDFS 仅在数据块大小 <= 要应用于计算的数据并且以单元形式打包的情况下才可行。

“每个人和他的兄弟”都在吹嘘 HDFS、S3 或等效物作为分布式计算的数据解决方案，在许多情况下，没有深入思考。最近我参与了一家处理广告领域大数据问题的公司。我需要跟踪和建模 4 亿+用户的浏览行为（url 访问），基于每天约 40 亿次广告拍卖，将每个 URL 与一个内容类别相关联（通过概念的分类和税制），并为每个用户确定一个特征向量。

我争辩说，使用 HDFS 对此数据进行处理将在扩展方面失败。问题在于拍卖数据，40 亿条<时间戳,用户,url, …>记录均匀地分布在 N 个节点上，而不是基于 userid MOD N。HDFS 不允许一个人控制数据/节点亲和性。我的计算是对每个用户在历史时期内看到的所有事件的一些函数。这个函数：

+   F( [<时间戳,用户 1,urlA, …>, <时间戳,用户 1,urlG, …>, …])

需要为每个用户评估，跨该用户的所有事件，并且不能合理地分解为单个事件上的子函数。我不得不使用的技术是在 HDFS 分布式时间序列上的 Spark。我争辩说，要为每个用户评估这个函数，平均而言，（N-1）/N 请求的数据需要从其他节点传输（因为只有 1/N 的数据可能在均匀分布的数据块方案中是本地的）。性能的（缺乏）并没有“令人失望”，相反，线性加速（N 倍快），产生了线性减速（由于通信的主导地位，接近 N 倍慢）。

**比特币交易所**

Bitcoin 通过区块链账本普及了许多关于去中心化清算、记账和信任的优秀理念。比特币背后的核心技术非常创新，正受到传统金融机构的密切关注。另一方面，交易所（有一些例外）似乎是在对金融领域之前的情况知之甚少的情况下建立起来的。

1.  JSON/REST 作为一种网络传输方式流行，但并不是市场数据的高效或精确传输。

    1.  线索：提供类似纳斯达克 ITCH 的二进制流基于传输以提高效率和精确度，或者如果你坚持的话，进行修复。

1.  一些交易所（如 Bitstamp）拥有超级慢的匹配引擎。

    1.  清扫订单簿需要数秒才能完成交易。

1.  将订单簿更新作为交易提供，而不是顶级 K 级别。

    1.  交易（新订单、删除订单、更新订单、成交）更加紧凑，提供更多信息，并且及时。

1.  提供关键帧。

    1.  即在连接时提供订单簿中订单的枚举，并在流中定期验证以启动订阅者的订单簿视图。
