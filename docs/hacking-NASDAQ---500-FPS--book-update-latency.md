<!--yml

分类: 未分类

日期: 2024-05-13 00:08:34

-->

# 以每秒 500 帧的速度入侵纳斯达克：书的更新延迟

> 来源：[`hackingnasdaq.blogspot.com/2009/12/rejection.html#0001-01-01`](http://hackingnasdaq.blogspot.com/2009/12/rejection.html#0001-01-01)

更新书籍的代码非常简单，有趣的问题是它能多快完成，因为这会给交易算法增加延迟，而这个空间都在讨论延迟。我的初步想法是，您希望在单台机器上为每个订单操作的每个符号更新书籍，因此需要每秒约 100k 条消息的吞吐量，这相当于每条消息约 10,000ns 或者约 41000 个周期 @4.1ghz... 这是一个很大的时间段，并且处理问题也不难。有趣的是优化延迟。

![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRug6conN-A3nYyVXAKoOizf3idGKJ79zx_BL3iGT7uYioUzBO03W1QK0kYGSjcEga9MdC6AMoakhDDlo6ZZ1KNXVACRSAJH8OX-HovgGfjW7g1yg2_K07g_yZcduHXSVeJ5OoO59LIg/s1600-h/highlevel_latency.jpg)

为什么延迟如此重要？因为交易所发送订单操作的响应时间，到交易所接收您的订单请求的时间才是重要的。因此，从交易所，经过以太网到您的服务器网卡，通过 Linux 网络堆栈，进入您的黑匣子交易算法，然后再通过 Linux 网络堆栈，到以太网卡，通过电线，返回给交易所。构建书籍是“黑匣子”的一部分，因此更新书籍所需的时间很重要。重要吗？这一点我不太确定，但是如果您的愚蠢代码仅仅更新书籍就需要 10,000 纳秒，那么您将在市场上吃大亏。

如何最小化书籍更新的延迟？实际上非常简单 - 每个 CPU 保留 1 个符号的书籍，或者如果您的交易是成对的，每个 CPU 保留几本书籍。如果您进行交易，可以为几个符号复制机器。为什么这有帮助？因为在比如说 Intel i7 处理器上，每个核心有 32KB x2（指令/数据）L1 缓存，每个核心有 256KB 的 L2 缓存，共享 8MB 的 L3。当执行延迟非常重要时，L1 缓存非常重要，L2 缓存接近至关重要，L3 缓存是你的神父，DDR 则是致命的。翻译 - 因为内存访问模式是相当随机的，尽量使工作数据集尽可能小，因此只在单个核心/CPU 插槽上处理几个符号，以便所有数据都留在芯片上，在缓存中。

这些数字是什么？据报道，L1 缺失需要 10 个周期（2.44ns @ 4.1Ghz），L2 缺失需要 30-40 个周期（9.76ns @ 4.1Ghz），如果你错过了 L3 并到达 DDR，你需要数百个周期，比如 400 个周期（97.6ns @ 4.1Ghz）。然而，英特尔工程师一直在努力让糟糕的代码在他们的硬件上快速运行，所以情况更复杂了，因为数据可以被预取，硬件可以在缺失时调度命中，还有 TLB 缺失的成本，或者可怕的是... 命中虚拟页面文件。故事的 morale 是尽可能保持内存占用尽可能小，并尽可能可预测地访问订单- 这是 x86 优化 101。

那么... 这很酷，但它与什么有关吗？简单。如果你的代码忙于花费 1000ns 处理符号 X 的订单簿，而你又在交易符号 Y，那么你刚刚浪费了 1000ns 的延迟，而符号 Y 的消息正在等待在缓冲区中被处理！那个时候，你的竞争对手已经在路上向交易所发送订单了，而你- 失败。因此，问题可以重新表述为“*拒绝消息的最快方法*”并且只处理你感兴趣的消息。

我的第一个想法是，很棒，只需对所有消息的股票符号进行 64 位比较，我们就完成了，太酷了.. 太容易了。然而，事情并不像那么简单，因为一切都围绕着唯一的 OrderID，这意味着你只有在订单添加消息中才能看到符号，而在所有其他订单类型中，你需要从 orderid 往回推断是否是相关的消息- 一个有趣的问题。
