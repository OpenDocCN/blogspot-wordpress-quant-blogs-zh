- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2024-05-18 05:47:35'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-18 05:47:35'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Trading Research/Idea Recommendation using Alternating Least Squares (ALS) |
    Tales from a Trading Desk
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨äº¤æ›¿æœ€å°äºŒä¹˜æ³•ï¼ˆALSï¼‰è¿›è¡Œäº¤æ˜“ç ”ç©¶/å»ºè®® | äº¤æ˜“æ¡Œä¸Šçš„æ•…äº‹
- en: æ¥æºï¼š[https://mdavey.wordpress.com/2014/08/07/trading-researchidea-recommendation-using-alternating-least-squares-als/#0001-01-01](https://mdavey.wordpress.com/2014/08/07/trading-researchidea-recommendation-using-alternating-least-squares-als/#0001-01-01)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://mdavey.wordpress.com/2014/08/07/trading-researchidea-recommendation-using-alternating-least-squares-als/#0001-01-01](https://mdavey.wordpress.com/2014/08/07/trading-researchidea-recommendation-using-alternating-least-squares-als/#0001-01-01)
- en: Trading Research/Idea Recommendation using Alternating Least SquaresÂ (ALS)
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨äº¤æ›¿æœ€å°äºŒä¹˜æ³•ï¼ˆALSï¼‰è¿›è¡Œäº¤æ˜“ç ”ç©¶/å»ºè®®
- en: '[Spark](http://spark.apache.org/docs/latest/streaming-programming-guide.html)
    is generating a lot of interest.Â  Obvious ideas for using Spark in the Single
    Bank Platform space is around helping the sell-sides clients in identify trade
    ideas/research/commentary to assist them in their portfolio.Â  As a starting point,
    its worth reading the Spark [movie](http://mlnick.github.io/blog/2013/04/01/movie-recommendations-and-more-with-spark/)
    recommendation with [MLib](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)
    [article](http://ampcamp.berkeley.edu/big-data-mini-course/movie-recommendation-with-mllib.html)
    over on ampcamp, which provides details on collaborative filtering and alternating
    least squares (ALS).Â  Code is also provided ğŸ™‚'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Spark](http://spark.apache.org/docs/latest/streaming-programming-guide.html)
    å¼•èµ·äº†å¾ˆå¤šäººå…³æ³¨ã€‚åœ¨å•ä¸€é“¶è¡Œå¹³å°ç©ºé—´ä½¿ç”¨Sparkçš„æ˜æ˜¾æƒ³æ³•æ˜¯å¸®åŠ©å–æ–¹å®¢æˆ·è¯†åˆ«äº¤æ˜“å»ºè®®/ç ”ç©¶/è¯„è®ºï¼Œä»¥ååŠ©ä»–ä»¬ç®¡ç†æŠ•èµ„ç»„åˆã€‚ä½œä¸ºä¸€ä¸ªèµ·ç‚¹ï¼Œé˜…è¯»Spark[ç”µå½±](http://mlnick.github.io/blog/2013/04/01/movie-recommendations-and-more-with-spark/)å»ºè®®å’Œ[MLlib](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)æ–‡ç« åœ¨ampcampä¸Šï¼Œæä¾›äº†ååŒè¿‡æ»¤å’Œäº¤æ›¿æœ€å°äºŒä¹˜æ³•ï¼ˆALSï¼‰çš„è¯¦ç»†ä¿¡æ¯ã€‚è¿˜æä¾›äº†ä»£ç 
    ğŸ™‚'
- en: '[MLlib](http://spark.apache.org/docs/latest/mllib-guide.html) is a Spark implementation
    of some common machine learning [algorithms](http://www.slideshare.net/MrChrisJohnson/collaborative-filtering-with-spark)
    and utilities, including classification, regression, clustering, collaborative
    filtering, dimensionality reduction, as well as underlying optimization primitives'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[MLlib](http://spark.apache.org/docs/latest/mllib-guide.html) æ˜¯Sparkå¯¹ä¸€äº›å¸¸è§æœºå™¨å­¦ä¹ [ç®—æ³•](http://www.slideshare.net/MrChrisJohnson/collaborative-filtering-with-spark)å’Œå·¥å…·çš„å®ç°ï¼ŒåŒ…æ‹¬åˆ†ç±»ã€å›å½’ã€èšç±»ã€ååŒè¿‡æ»¤ã€ç»´åº¦é™ä½ä»¥åŠåº•å±‚ä¼˜åŒ–åŸè¯­ã€‚'
- en: Its probably also having a read of the ampcampâ€™s Spark Streaming [article](http://ampcamp.berkeley.edu/3/exercises/realtime-processing-with-spark-streaming.html).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸è¿˜ä¼šé˜…è¯»ampcampçš„Spark Streaming[æ–‡ç« ](http://ampcamp.berkeley.edu/3/exercises/realtime-processing-with-spark-streaming.html)ã€‚
- en: 'Finally, check out Andrew Psaltisâ€™s video, Real-time Map Reduce: Exploring
    Clickstream [Analytics](http://berlinbuzzwords.de/session/real-time-map-reduce-exploring-clickstream-analytics-spark-streaming-kafka-and-websockets)
    with Spark Streaming, Kafka and WebSockets'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œçœ‹çœ‹Andrew Psaltisçš„è§†é¢‘ï¼Œæ¢ç´¢ç‚¹å‡»æµåˆ†æçš„å®æ—¶Map Reduceï¼š[http://berlinbuzzwords.de/session/real-time-map-reduce-exploring-clickstream-analytics-spark-streaming-kafka-and-websockets](http://berlinbuzzwords.de/session/real-time-map-reduce-exploring-clickstream-analytics-spark-streaming-kafka-and-websockets)
- en: With all the above, its relatively easy to begin to look at using Spark Streaming
    to deliver alerts to client on recommended reading material.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†ä¸Šè¿°æ‰€æœ‰å†…å®¹ï¼Œå¼€å§‹ä½¿ç”¨Spark Streamingå‘å®¢æˆ·æä¾›æ¨èé˜…è¯»ææ–™çš„è­¦æŠ¥ç›¸å¯¹å®¹æ˜“ã€‚
- en: 'For a deep understanding of what is going on, try this [article](http://labs.yahoo.com/files/HuKorenVolinsky-ICDM08.pdf).Â 
    Be mindful of the â€˜cold startâ€™ issue:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ·±å…¥ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆï¼Œè¯•è¯•è¿™ç¯‡[æ–‡ç« ](http://labs.yahoo.com/files/HuKorenVolinsky-ICDM08.pdf)ã€‚è¦ç•™æ„â€œå†·å¯åŠ¨â€é—®é¢˜ï¼š
- en: inability to address products new to the system, for which content based approaches
    would be adequate.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ— æ³•å¤„ç†ç³»ç»Ÿä¸­çš„æ–°äº§å“ï¼Œå†…å®¹åŸºç¡€æ–¹æ³•å°†è¶³å¤Ÿã€‚
- en: Taking this a step further, user data and trade content with trading activity,
    quoting activity and possible CRM data would enhance the recommendations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´è¿›ä¸€æ­¥ï¼Œç”¨æˆ·æ•°æ®å’Œäº¤æ˜“å†…å®¹ç»“åˆäº¤æ˜“æ´»åŠ¨ã€æŠ¥ä»·æ´»åŠ¨ä»¥åŠå¯èƒ½çš„å®¢æˆ·å…³ç³»ç®¡ç†ï¼ˆCRMï¼‰æ•°æ®å°†å¢å¼ºå»ºè®®ã€‚
- en: Finally, it would be interesting to know if you could take advantage of Collaborative
    [Filtering](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)
    from a spreading perspective, to possible recommend a spread on the trade price
    for an instrument.Â  Logistic [Regression](https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression)
    maybe more interesting for optimize the client spread based on the price sensitivity
    from RFQ accept/reject data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œäº†è§£ä¸€ä¸‹ä½ æ˜¯å¦èƒ½ä»ä¼ æ’­çš„è§’åº¦åˆ©ç”¨ååŒè¿‡æ»¤[ç®—æ³•](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)ï¼Œæ¥å¯èƒ½åœ°æ¨èä¸€ç§å…³äºäº¤æ˜“ä»·æ ¼çš„ä¼ æ’­ï¼Œä¼šå¾ˆæœ‰è¶£ã€‚
    logistics [å›å½’](https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression)æˆ–è®¸å¯¹äºæ ¹æ®RFQæ¥å—/æ‹’ç»æ•°æ®çš„ä»·æ ¼æ•æ„Ÿæ€§æ¥ä¼˜åŒ–å®¢æˆ·ä¼ æ’­æ›´ä¸ºæœ‰è¶£ã€‚
- en: ~ by mdavey on August 7, 2014.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ~ mdaveyäº2014å¹´8æœˆ7æ—¥ã€‚
- en: Posted in [Data](https://mdavey.wordpress.com/category/data/)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å‘å¸ƒåœ¨[æ•°æ®](https://mdavey.wordpress.com/category/data/)åˆ†ç±»ä¸­ã€‚
