- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-12 17:51:26'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-12 17:51:26'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: CRSM Regression | CSSA
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CRSM 回归 | CSSA
- en: 来源：[https://cssanalytics.wordpress.com/2014/11/07/crsm-regression/#0001-01-01](https://cssanalytics.wordpress.com/2014/11/07/crsm-regression/#0001-01-01)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://cssanalytics.wordpress.com/2014/11/07/crsm-regression/#0001-01-01](https://cssanalytics.wordpress.com/2014/11/07/crsm-regression/#0001-01-01)
- en: 'In the last post, I presented a schematic of how [Cluster Random Subspace (CRSM)](https://cssanalytics.wordpress.com/2014/11/05/cluster-random-subspace-a-process-diagram/
    "Cluster Random Subspace- A Process Diagram") would work for portfolio optimization.
    But the concept can be extended to prediction and classification. Obviously “Random
    Forests” could incorporate this concept to build superior decision trees with
    fewer samples–but I would caution that decision trees tend to have poor performance
    for prediction of financial time series (this is due to binary thresholding and
    over-fitting). However, standard multiple regression has been a workhorse in finance
    simply because it is more robust and less prone to over-fitting than other machine-learning
    approaches. One of the challenges in regression is that it breaks down when you
    have a lot of variables to choose from and some of them are highly correlated.
    There are many established ways for dealing with this problem (PCA, stepwise regression
    etc), but CRSM remains an excellent candidate since it can be used to form a robust
    ensemble forecast from a large group of predictors. It does not address the initial
    choice of variables, but at least it can automatically handle a large group of
    candidates that may contain some highly correlated variables. CRSM Regression
    is a good way to proceed when you have a lot of possible indicators, but don’t
    have any pre-conceived ideas for constructing a good model. Here is a process
    diagram for one of many possible methods to apply CRSM Regression:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一篇文章中，我介绍了如何使用[聚类随机子空间（CRSM）](https://cssanalytics.wordpress.com/2014/11/05/cluster-random-subspace-a-process-diagram/
    "聚类随机子空间-过程图解")进行投资组合优化的示意图。但这个概念可以扩展到预测和分类。显然，“随机森林”可以将这个概念纳入，以用更少的样本构建优秀的决策树——但我要警告说，决策树在预测金融时间序列时往往表现不佳（这是由于二元阈值化和过拟合导致的）。然而，标准的多元回归在金融领域一直是一个重要工具，因为它比其他机器学习方法更稳健，不容易过拟合。回归的一个挑战是当你有很多变量可供选择时，其中一些变量高度相关时，它就会崩溃。有许多已建立的解决此问题的方法（PCA、逐步回归等），但
    CRSM 仍然是一个优秀的选择，因为它可以从大量的预测变量中形成一个稳健的集成预测。它并不解决变量的初始选择，但至少它可以自动处理可能包含一些高度相关变量的大量候选变量。CRSM
    回归是一个很好的方法，当你有很多可能的指标，但没有任何预先构建一个好模型的想法时。这是一个应用 CRSM 回归的许多可能方法的流程图之一：
- en: '[![crsm-regression](img/325778bc640b2b032bf14b6ae8e581d4.png)](https://cssanalytics.files.wordpress.com/2014/11/crsm-regression2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[![crsm-regression](img/325778bc640b2b032bf14b6ae8e581d4.png)](https://cssanalytics.files.wordpress.com/2014/11/crsm-regression2.png)'
